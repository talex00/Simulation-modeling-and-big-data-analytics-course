{"cells":[{"cell_type":"markdown","metadata":{"id":"_DsfDI6DqBtO"},"source":["# Лабораторная работа № 5. Решение задачи классификации на примере прогноза состояния системы на основе данных о состоянии ее компонентов."]},{"cell_type":"markdown","metadata":{"id":"VmbTnG0-qBtc"},"source":["В работе проводится ознакомление с различными методами машинного обучения с учителем, решающих задачу классификации. СОздаются различные линейные и нелинейные модели и оценивается точность из прогноза."]},{"cell_type":"markdown","metadata":{"id":"aV2fRv3aqBtg"},"source":["## Введение"]},{"cell_type":"markdown","metadata":{"id":"EjyHwi_EqBti"},"source":["Современные радиолокационные станции (РЛС) – это структурно-сложные радиотехнические и информационные системы, характеризующиеся высокой надежностью функционирования и большим числом цифровых компонентов в своем составе. Одним из таких компонентов является блок усиления мощности (БУМ), задача которого усиливать передаваемый или принимаемый сигнал.\n","\n","Функционирование БУМ приводит к их нагреву, что может сказаться на снижении их работоспособности или даже привести к отказу. Под системой в этой работе мы будем понимать несколько БУМ, объединенных в единое целое. Тогда техническое состояние всей системы будет определяться техническим состоянием ее компонент, т.е. состоянием БУМ в данной работе. Техническое же состояние БУМ напрямую зависит от их температуры: при достижении определенного порога блок перестает работать и начинает охлаждаться. После охлаждения до определенной температуры он снова переходит в рабоспособное состояние.\n","\n","Основная задача - спрогнозировать увеличение температуры блоков усиления мощности на основании истории их функционирования и режима работы блоков, который задает интенсивность нагрева, и возможный выход из строя всей системы блоков. В лабораторной работе № 3 проводится статистический анализ данных тепловой нагрузки модельных БУМ, определяются пороговые значения температур, при которых происходит отключение блоков с целью их охлаждения. На основании пороговых температур вычислено состояние блоков в интервале \\[0, 1\\] и установлен простой критерий определения состояния системы - снижение среднего состояния всех блоков ниже определенного порогового значения. \n","\n","В данной лабораторной работе будут применены различные методы машинного обучения с учителем для установления зависимости состояния системы от состояний блоков и прогноза состояния системы."]},{"cell_type":"markdown","metadata":{"id":"_S9KJFqHqBtm"},"source":["## Описание исходных данных"]},{"cell_type":"markdown","metadata":{"id":"u4j3rBTXqBto"},"source":["Подключим стандартные пакеты для работы с данными и построения графиков"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjwqQJm5qBtq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5Ed3QNatqBtw"},"source":["Загрузим файл с данными и выведем на экран первые 5 строк. Получим информацию по каждой колонке."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxSFtxYEqBty"},"outputs":[],"source":["df = pd.read_csv(\"Lab5_data.csv\")\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKlxfuswqBt1"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"VgrvAO1VqBt2"},"source":["Колонки **state1 - state9** содержат состояние блока 1 - 9 в виде вещественного числа в интервале \\[0, 1\\]. При этом значению 1 соответствует работоспособное состояние с минимальной температурой, в состоянию 0 - выключенное состояние, когда блок находится в режиме обхлаждения. Колонка **system_state** обозначает состояние системы: 1 - работоспособна, 0 - нерабоспособна. Все колонки имеют тип **float64**."]},{"cell_type":"markdown","metadata":{"id":"mt-LyBPmqBt4"},"source":["## Подготовка данных"]},{"cell_type":"markdown","metadata":{"id":"uIKiNU2qqBt5"},"source":["Для использования моделей машинного обучения с учителем необходимо специальным образом подготовить данные: сформировать обучающую выборку, на которой модель будет \"учиться\", т.е. подстраивать свои внутренние параметры, тестовую выборку, на которой будет определяться точность модели в процессе ее обучения, а также валидационную выборку, на которой проверяется итогое качество работы модели. \n","\n","Вместо выделения валидационной выборки можно использовать механизм кросс-валидации.В основе метода лежит разделение исходного множества данных на **k** примерно равных блоков, например 5. Затем на **k-1**, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется **k** раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.\n","![Cross-validation](https://wiki.loginom.ru/images/cross-validation.svg)"]},{"cell_type":"markdown","metadata":{"id":"L-clFbuQqBt7"},"source":["Кросс-валидация имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели:\n","\n","- Распределение классов оказывается более равномерным, что улучшает качество обучения.\n","- Если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная оценка будет более достоверной.\n","\n","В дальнейшем в этой лабораторной работе будем использовать разбиение на 5 блоков с помощью метода **[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=k%20fold#sklearn.model_selection.KFold 'KFold')**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbvqQcwKqBt9"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","X = df.loc[:, 'state1':'state9']\n","y = df['system_state'].astype(int)\n","\n","for i, (train_index, test_index) in enumerate(kf.split(X), start=1):\n","    print('Fold {}'.format(i))\n","    print('Train index: ', train_index)\n","    print('Test index: ', test_index)"]},{"cell_type":"markdown","metadata":{"id":"EJuzMzGlqBt_"},"source":["## Линейные модели машинного обучения"]},{"cell_type":"markdown","metadata":{"id":"_LeJCG4YqBt_"},"source":["Задача определения состояния системы по известным состояниям блоков является задачей бинарной классификации. Среди линейных моделей будем использовать линейную регрессию, линейную регрессию с L1 и L2-регуляризацией, а также логистическую регрессию. Подробное описание работы этих моделей можно прочитать на сайте [Scikit Learn](https://scikit-learn.org/stable/modules/linear_model.html 'Scikit Learn')."]},{"cell_type":"markdown","source":["#### **Задание 1** "],"metadata":{"id":"4q9msIwFqEL8"}},{"cell_type":"markdown","metadata":{"id":"gR_4Iew-qBuB"},"source":["Сделаем процесс обучения различных моделей универсальным. Для этого напишем функцию **regr_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели регрессии, функцию **class_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели классификации, и функцию **train(model, model_name, evaluate, kfold, X, y)**, которая обучает заданную модель **model** с использованием механизма кросс-валидации **kfold**.\n","\n","Точность - относительная доля правильно спрогнозированных значений."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XlMFRASqBuC"},"outputs":[],"source":["def regr_accuracy(y_pred, y_test):\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","    \n","    # напишите здесь ваш код\n","    \n","    return 0\n","\n","def class_accuracy(y_pred, y_test):\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","    \n","    # напишите здесь ваш код\n","    \n","    return 0\n","\n","def train(model, model_name, evaluate, kfold, X, y):\n","    # model - модель для прогноза, обладающая методами fit(), predict()\n","    # model_name - название модели, строковый тип\n","    # evaluate - функция для расчета точности, например функция regr_accuracy() или class_accuracy()\n","    # kfold - объект KFold\n","    # X - признаки\n","    # y - целевая переменная\n","    print('Train model: '+model_name)\n","    scores = []\n","    for train_index, test_index in kfold.split(X):\n","        \n","        # напишите здесь ваш код\n","        \n","    mean_score = np.mean(scores)\n","    print('Mean score = {:.5f}'.format(mean_score))\n","    return mean_score"]},{"cell_type":"markdown","metadata":{"id":"B5yEVTk8qBuE"},"source":["### Линейная регрессия"]},{"cell_type":"markdown","metadata":{"id":"o1LF2lQXqBuF"},"source":["В линейных моделях целевая переменная $\\hat{y}$ определяется как линейная комбинация известных переменных (признаков):\n","\n","$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n","\n","В модели линейной регрессии коэффициенты $w = (w_1, ..., w_p)$ подбираются таким образом, чтобы минимизировать сумму квадратов отклонений рассчитанных значений целевой переменной от истинных значений:\n","\n","$$\\min_{w} || X w - y||_2^2$$\n","\n","Важно отметить, что линейные модели чувствительны к абсолютным значениям признаков, поэтому следует перед применением линейных моделей провести нормирование исходных данных (обычно на интервал \\[0,1\\]). Также применение линейных моделей основано на предположении о линейной независимости признаков, поэтому следует стараться не использовать в качестве признаков коррелированные признаки. В противном случае модель будет чувствительна к шумам, т.е. случайным выбросам в значениях признаков."]},{"cell_type":"markdown","metadata":{"id":"ZrfRKpNhqBuG"},"source":["Создадим и обучим модель **[LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression 'LinearRegression')**. Запишем точность модели в словарь **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1yueQNJqBuH"},"outputs":[],"source":["from sklearn import linear_model\n","\n","lin_reg = linear_model.LinearRegression()\n","\n","scores = dict()\n","\n","score = train(lin_reg, 'linear regression', regr_accuracy, kf, X, y)\n","scores['linear regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"8SOVicj5qBuI"},"source":["### Линейная регрессия c L1 и L2 регуляризацией"]},{"cell_type":"markdown","metadata":{"id":"DGNWt1qDqBuJ"},"source":["Если размер обучающей выборки невелик, а число признаков, наоборот, достаточно велико, то коэффициенты модели могут быть подобраны таким образом, чтобы модель максимально точно учитывала все точки из обучающей выборки, при этом вне обучающей выборки модель будет давать большую ошибку. Это явление носит название переобучения. Одним из способов препятствовать переобучению является механизмы регуляризации. Он ограничивает значения коэффицентов $w = (w_1, ..., w_p)$, используемых в модели.\n","\n","L1-регуляризация вносит дополнительный \"штраф\", пропорциональный модулю значения коэффициента:\n","$$\\min_{w} ||X w - y||_2 ^ 2 + \\alpha ||w||_1$$\n","\n","L2-регуляризация вносит дополнительный \"штраф\", пропорциональный квадрату модуля значения коэффициента:\n","$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2$$\n","\n","Параметр $\\alpha$ задает \"силу\" регуляризации. L1-регуляризация приведет к тому, что все несущественные признаки будут иметь вес, равный 0. L2-регуляризация приведет к тому, что несущественные признаки будут иметь околонулевые веса. Продемонстрируем это на примере. Создадим и обучим модели **[Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso 'Lasso')** (L1-регуляризация) и **[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge 'Ridge')** (L2-регуляризация).\n","\n","Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Lasso**."]},{"cell_type":"markdown","source":["#### **Задание 2** "],"metadata":{"id":"WA9AmWF9qRZ4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbZqmJWUqBuJ"},"outputs":[],"source":["for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","    \n","    # напишите здесь ваш код\n","    \n","    print('Coefficients: ', lasso.coef_)"]},{"cell_type":"markdown","metadata":{"id":"bEtMb7HnqBuK"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijIaEpdmqBuK"},"outputs":[],"source":["lasso = linear_model.Lasso(alpha = )\n","score = train(lasso, 'lasso', regr_accuracy, kf, X, y)\n","scores['lasso'] = score"]},{"cell_type":"markdown","source":["#### **Задание 3** "],"metadata":{"id":"lT6aVlFvqUWP"}},{"cell_type":"markdown","metadata":{"id":"jC4eciIHqBuL"},"source":["Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Ridge**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbCQ_NzuqBuM"},"outputs":[],"source":["# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"Mx1E56OwqBuM"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvicDflUqBuM"},"outputs":[],"source":["ridge = linear_model.Ridge(alpha = )\n","score = train(ridge, 'ridge', regr_accuracy, kf, X, y)\n","scores['ridge'] = score"]},{"cell_type":"markdown","metadata":{"id":"V18B9WFqqBuN"},"source":["Как видим, **Lasso** просто занулила все коэффициенты при $\\alpha>0.01$."]},{"cell_type":"markdown","metadata":{"id":"_bm3DSxiqBuN"},"source":["### Логистическая регрессия"]},{"cell_type":"markdown","metadata":{"id":"Zk3mvsA_qBuO"},"source":["Если на выходе линейной регрессии получается просто вещественное число, то в логистической регрессии это число преобразуется с помощью логистической функции в отрезок \\[0,1\\], а потому может трактоваться как вероятность получения на выходе дискретного значения 1. \n","\n","$$f(y)=\\dfrac{1}{1+e^{-y}}$$\n","\n","Таким образом, модель логистической регрессии может успешно использоваться как бинарный классификатор. Логистическая регрессия минимизирует следующую величину (L1 и L2 регуляризация уже включены и контролируются параметрами $C$ - \"сила\" регуляризации (малые значения - \"сильная\" регуляризация), $\\rho$ - относительный вклад L1-регуляризации):\n","\n","$$\\min_{w, c} \\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1)$$\n","\n","Создадим модель **[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression 'Logistic Regression')** и обучим ее.\n","\n","Подберите оптимальное значение параметра регуляризации **С** и тип регуляризации **penalty**. "]},{"cell_type":"markdown","source":["#### **Задание 4** "],"metadata":{"id":"N5CGOf2GqeeK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1P4VdrGSqBuP"},"outputs":[],"source":["# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"IW1aI40TqBuP"},"source":["Обучим модель с оптимальным значением параметра **С**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cctaYPAcqBuP"},"outputs":[],"source":["logistic_regr = linear_model.LogisticRegression(penalty = , C=, solver='lbfgs')\n","score = train(logistic_regr, 'logistic regression', class_accuracy, kf, X, y)\n","scores['logistic regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"wYfkTsd0qBuQ"},"source":["## Метод опорных векторов"]},{"cell_type":"markdown","metadata":{"id":"NdFpL7e3qBuQ"},"source":["Этот метод применим для решения как задач классификации, так и регрессии, и кластеризации. Основными достоинствами метода являются:\n","\n","- эффективность при большой размерности пространства признаков\n","- в процессе обучения запоминается только подвыборка обучающей выборки - опорные вектора, т.е. требует меньший объем памяти\n","- можно применять разные ядра (kernels) для формирования модели\n","\n","Недостатком метода опорных векторов является то, что в случае, когда размерность пространства признаков много больше объема обучающей выборки, на результат работы модели сильно влияет выбор ядра. Также этот метод не позволяет быстро и просто получить вероятность прогноза.\n","\n","С математической точки зрения, метод опорных векторов проводит гипер-плоскость, которая разделяет один класс от другого. При этом граница проводится так, что быть расположенной максимально далеко от каждой из точек.\n","![SVC](https://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png)\n","\n","Функция ядра определяет, какие признаки будут использоваться в качестве переменных в гиперпространстве, в котором проводится гипер-плоскость. Например, для линейного ядра $\\langle x, x'\\rangle$ берутся исходные признаки, для полиномиального ядра - полиномы от исходных признаков $(\\gamma \\langle x, x'\\rangle + r)^d$, для radial-basis-function (rbf) - экспоненциальная функция $\\exp(-\\gamma \\|x-x'\\|^2)$.\n","\n","Построим модель Support Vector Classifier - [**SVC**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC 'SVC') для различных ядер. Заранее уменьшим размер выборки, что позволит проводить обучения в разумное время (метод опорных векторов довольно долго обучается).\n","\n","Определите оптимальное значение параметра регуляризации **С** и типа ядра **kernel**."]},{"cell_type":"markdown","source":["#### **Задание 5**"],"metadata":{"id":"ivF5OJxVqhSq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0bgmnaoqBuR"},"outputs":[],"source":["from sklearn.svm import SVC\n","X_svc = X.iloc[:10000, :]\n","y_svc = y[:10000]\n","\n","# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"sfsLap6cqBuR"},"source":["Обучим модель с оптимальным значением параметра **С** и типом ядра **kernel**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scitVGNbqBuS"},"outputs":[],"source":["svc = SVC(C=, kernel=, gamma='auto')\n","score = train(svc, 'svc', class_accuracy, kf, X_svc, y_svc)\n","scores['svc'] = score"]},{"cell_type":"markdown","metadata":{"id":"VNehNP8gqBuS"},"source":["## Дерево решений"]},{"cell_type":"markdown","metadata":{"id":"UP-bW4hwqBuS"},"source":["В модели дерева решений (Decision Tree) в процессе обучения строится алгоритм, по которому выполняется прогноз модели. При этом алгоритм представляет из себя дерево, каждый лист которого - это проверка на то, что какой-либо признак из обучающей выборки принимает определенное значение. Пример дерева решений приведен на рисунке ниже.\n","![Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png)\n","\n","Преимуществами такого метода являются:\n","- простота визуализации и хорошая интерпретируемость алгоритма прогноза\n","- не требуется нормализация данных\n","- скорость прогноза пропорциональна логарифму объема выборки, т.е. этот метод быстрый\n","- может обрабатывать как числовые, так и категориальные данные\n","\n","Недостатками метода являются:\n","- деревья легко переобучаются\n","- небольшие изменения в обучающей выборке могут привести к перестойке всего дерева, т.е. метод нестабилен\n","- предсказания деревьев являются кусочно-постоянными, поэтому не годятся для экстраполирования\n","- требуется сбалансировать обучающую выборку по классам, чтобы не допустить \"перекоса\" дерева в сторону какого-либо класса\n","\n","Конкретную математическую реализалицаю алгоритма построения дерева решений можно изучить, например, [здесь.](https://scikit-learn.org/stable/modules/tree.html)\n","\n","Создадим модель [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier 'DecisionTreeClassifier') и обучим ее. Для того, чтобы предотвратить переобучение дерева, обычно ограничивается максимальная глубина дерева - параметр **max_depth**, а также минимальное число элементов из обучающей выборки, приходящееся на определнный лист, чтобы можно было с него сделать новое ветвление - параметр **min_samples_split**.\n","\n","Подберите оптимальное значение параметров **max_depth** и **min_samples_split**."]},{"cell_type":"markdown","source":["#### **Задание 6** "],"metadata":{"id":"3dc10J6-qq_P"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSShPADxqBuT"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# напишите здесь ваш код"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQExOWvOqBuT"},"outputs":[],"source":["# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"NJB7z7RiqBuU"},"source":["Создадим модель с оптимальными значениями параметров **max_depth** и **min_samples_split**. Добавим ее в словарь **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STjh7rAuqBuU"},"outputs":[],"source":["dtc = DecisionTreeClassifier(max_depth=, min_samples_split=, min_samples_leaf=1, random_state=0)\n","score = train(dtc, 'decision tree', class_accuracy, kf, X, y)\n","scores['decision tree'] = score"]},{"cell_type":"markdown","metadata":{"id":"L54zzd7KqBuU"},"source":["## Сравнение различных моделей"]},{"cell_type":"markdown","metadata":{"id":"xEaMPqy-qBuU"},"source":["Отобразим на графике точность работы каждой построенной модели. Для этого будем использовать значения из словаря **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6SRzljXqBuV"},"outputs":[],"source":["plt.figure(figsize=(10,5))\n","xx = list(scores.keys())\n","yy = list(scores.values())\n","rects = plt.bar(xx, yy)\n","plt.ylim(0.7, 0.9)\n","plt.ylabel('Accuracy')\n","for i, rect in enumerate(rects):\n","    yloc = rect.get_height()\n","    xloc = rect.get_x() + rect.get_width() / 4\n","    plt.annotate(round(yy[i], 4), xy=(xloc, yloc), xytext=(xloc, 10),\n","                            textcoords=\"offset points\",\n","                            va='center',\n","                            color='black', clip_on=True)"]},{"cell_type":"markdown","metadata":{"id":"mFqOwK_mqBuV"},"source":["# Выводы"]},{"cell_type":"markdown","source":["#### **Задание 7** "],"metadata":{"id":"u_haAZPuqwqf"}},{"cell_type":"markdown","metadata":{"id":"XXjkE-WUqBuV"},"source":["Напишите выводы по лабораторной работе"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfKKrNttqBuW"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}